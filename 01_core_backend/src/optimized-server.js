/**\n * Optimized Express Server Configuration\n * High-performance setup with compression, caching, and monitoring\n */\n\nconst express = require('express');\nconst compression = require('compression');\nconst helmet = require('helmet');\nconst rateLimit = require('express-rate-limit');\nconst cors = require('cors');\nconst responseTime = require('response-time');\nconst cluster = require('cluster');\nconst os = require('os');\nconst { createProxyMiddleware } = require('http-proxy-middleware');\nconst NodeCache = require('node-cache');\n\n// Import optimized utilities\nconst { db, initializeDatabase } = require('./utils/railway-database');\nconst logger = require('./utils/logger');\n\n// Performance monitoring\nconst performanceCache = new NodeCache({ stdTTL: 300 }); // 5 minute cache\nlet serverMetrics = {\n  totalRequests: 0,\n  averageResponseTime: 0,\n  errorRate: 0,\n  cacheHitRate: 0\n};\n\n// Clustering for production\nif (cluster.isMaster && process.env.NODE_ENV === 'production') {\n  const numWorkers = Math.min(4, os.cpus().length); // Limit to 4 workers\n  \n  console.log(`\ud83d\ude80 Master process starting ${numWorkers} workers...`);\n  \n  for (let i = 0; i < numWorkers; i++) {\n    cluster.fork();\n  }\n  \n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`\u26a0\ufe0f Worker ${worker.process.pid} died. Restarting...`);\n    cluster.fork();\n  });\n  \n  return;\n}\n\nconst app = express();\nconst PORT = process.env.PORT || 3000;\n\n// MARK: - Enhanced Middleware Stack\n\n// Security & Performance\napp.use(helmet({\n  contentSecurityPolicy: {\n    directives: {\n      defaultSrc: [\"'self'\"],\n      scriptSrc: [\"'self'\", \"'unsafe-inline'\"],\n      styleSrc: [\"'self'\", \"'unsafe-inline'\"],\n      imgSrc: [\"'self'\", \"data:\", \"https:\"],\n    },\n  },\n}));\n\n// Compression with optimized settings\napp.use(compression({\n  level: 6, // Good balance of compression vs CPU\n  threshold: 1024, // Only compress responses > 1KB\n  filter: (req, res) => {\n    // Compress JSON, text, and HTML\n    return /json|text|html|javascript|css/.test(res.getHeader('content-type'));\n  }\n}));\n\n// Response time tracking\napp.use(responseTime((req, res, time) => {\n  // Update metrics\n  serverMetrics.totalRequests++;\n  serverMetrics.averageResponseTime = \n    (serverMetrics.averageResponseTime * (serverMetrics.totalRequests - 1) + time) / serverMetrics.totalRequests;\n  \n  // Log slow requests\n  if (time > 1000) {\n    logger.warn(`Slow request: ${req.method} ${req.path} - ${time.toFixed(2)}ms`);\n  }\n}));\n\n// Enhanced CORS with performance optimization\napp.use(cors({\n  origin: function (origin, callback) {\n    // Allow requests from known domains or localhost in development\n    const allowedOrigins = [\n      'https://studyai-app.netlify.app',\n      'https://sai-backend-production.up.railway.app',\n      'http://localhost:3000',\n      'http://localhost:3001'\n    ];\n    \n    if (!origin || allowedOrigins.includes(origin)) {\n      callback(null, true);\n    } else {\n      callback(new Error('Not allowed by CORS'));\n    }\n  },\n  credentials: true,\n  methods: ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'],\n  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With'],\n  maxAge: 86400 // Cache preflight requests for 24 hours\n}));\n\n// Tiered rate limiting\nconst createRateLimit = (windowMs, max, message) => rateLimit({\n  windowMs,\n  max,\n  message: { error: message },\n  standardHeaders: true,\n  legacyHeaders: false,\n  // Use Redis store in production for distributed rate limiting\n  store: process.env.REDIS_URL ? new (require('rate-limit-redis'))({ \n    sendCommand: (...args) => redisClient.call(...args) \n  }) : undefined\n});\n\n// Apply different rate limits for different endpoints\napp.use('/api/auth', createRateLimit(15 * 60 * 1000, 10, 'Too many authentication attempts'));\napp.use('/api/ai', createRateLimit(60 * 1000, 20, 'Too many AI requests'));\napp.use('/api', createRateLimit(15 * 60 * 1000, 100, 'Too many requests'));\n\n// Enhanced JSON parsing with size limits\napp.use(express.json({ \n  limit: '10mb', // Reasonable limit for image uploads\n  verify: (req, res, buf, encoding) => {\n    // Add request size to metrics\n    req.contentLength = buf.length;\n  }\n}));\n\napp.use(express.urlencoded({ extended: true, limit: '10mb' }));\n\n// Request logging and metrics\napp.use((req, res, next) => {\n  req.startTime = Date.now();\n  \n  // Log incoming requests (sample in production)\n  if (process.env.NODE_ENV === 'development' || Math.random() < 0.1) {\n    logger.info(`${req.method} ${req.path}`, {\n      userAgent: req.get('User-Agent'),\n      contentLength: req.contentLength || 0,\n      ip: req.ip\n    });\n  }\n  \n  next();\n});\n\n// MARK: - Performance Monitoring Endpoint\n\napp.get('/api/metrics', (req, res) => {\n  const memoryUsage = process.memoryUsage();\n  const uptime = process.uptime();\n  \n  res.json({\n    server: {\n      uptime: Math.floor(uptime),\n      memory: {\n        rss: Math.round(memoryUsage.rss / 1024 / 1024), // MB\n        heapUsed: Math.round(memoryUsage.heapUsed / 1024 / 1024), // MB\n        heapTotal: Math.round(memoryUsage.heapTotal / 1024 / 1024), // MB\n        external: Math.round(memoryUsage.external / 1024 / 1024) // MB\n      },\n      requests: serverMetrics,\n      worker: process.pid\n    }\n  });\n});\n\n// Health check with database connectivity\napp.get('/health', async (req, res) => {\n  try {\n    // Quick database health check\n    const dbStart = Date.now();\n    await db.query('SELECT 1');\n    const dbLatency = Date.now() - dbStart;\n    \n    res.json({\n      status: 'healthy',\n      timestamp: new Date().toISOString(),\n      uptime: process.uptime(),\n      database: {\n        status: 'connected',\n        latency: `${dbLatency}ms`\n      },\n      worker: process.pid\n    });\n  } catch (error) {\n    res.status(503).json({\n      status: 'unhealthy',\n      error: error.message,\n      timestamp: new Date().toISOString(),\n      worker: process.pid\n    });\n  }\n});\n\n// MARK: - Route Imports (these would be your existing routes)\n// Import and use your existing route files here\n// const authRoutes = require('./routes/auth');\n// const aiRoutes = require('./routes/ai');\n// app.use('/api/auth', authRoutes);\n// app.use('/api/ai', aiRoutes);\n\n// MARK: - Error Handling Middleware\n\n// 404 handler\napp.use('*', (req, res) => {\n  res.status(404).json({\n    error: 'Endpoint not found',\n    path: req.originalUrl,\n    method: req.method\n  });\n});\n\n// Global error handler\napp.use((err, req, res, next) => {\n  // Update error rate metric\n  serverMetrics.errorRate = (serverMetrics.errorRate * 0.9) + 0.1;\n  \n  logger.error('Unhandled error:', {\n    error: err.message,\n    stack: err.stack,\n    path: req.path,\n    method: req.method,\n    userAgent: req.get('User-Agent')\n  });\n  \n  // Don't leak error details in production\n  const errorResponse = {\n    error: process.env.NODE_ENV === 'production' ? 'Internal server error' : err.message,\n    timestamp: new Date().toISOString()\n  };\n  \n  if (process.env.NODE_ENV === 'development') {\n    errorResponse.stack = err.stack;\n  }\n  \n  res.status(err.status || 500).json(errorResponse);\n});\n\n// MARK: - Server Startup\n\nasync function startServer() {\n  try {\n    // Initialize database\n    await initializeDatabase();\n    \n    // Start server\n    const server = app.listen(PORT, () => {\n      console.log(`\ud83d\ude80 Optimized StudyAI server running on port ${PORT}`);\n      console.log(`\ud83d\udd0d Worker PID: ${process.pid}`);\n      console.log(`\ud83c\udf0d Environment: ${process.env.NODE_ENV || 'development'}`);\n    });\n    \n    // Graceful shutdown\n    const gracefulShutdown = (signal) => {\n      console.log(`\ud83d\udeaa Received ${signal}. Starting graceful shutdown...`);\n      \n      server.close(() => {\n        console.log('\u2705 HTTP server closed.');\n        \n        // Close database connections\n        if (db.end) {\n          db.end(() => {\n            console.log('\u2705 Database connections closed.');\n            process.exit(0);\n          });\n        } else {\n          process.exit(0);\n        }\n      });\n    };\n    \n    process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));\n    process.on('SIGINT', () => gracefulShutdown('SIGINT'));\n    \n  } catch (error) {\n    console.error('\u274c Failed to start server:', error);\n    process.exit(1);\n  }\n}\n\n// Only start server if this is a worker process or not clustered\nif (!cluster.isMaster || process.env.NODE_ENV !== 'production') {\n  startServer();\n}\n\nmodule.exports = app;"