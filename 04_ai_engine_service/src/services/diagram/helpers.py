# -*- coding: utf-8 -*-
"""
Diagram generation helper functions
"""
import json as _json
import re
from typing import Dict, Optional

# PRODUCTION: Structured logging
from ..logger import setup_logger

# Initialize logger
logger = setup_logger(__name__)


def extract_json_from_responses(response):
    """
    Cross-version helper to extract JSON from OpenAI Responses API.

    Works across different SDK versions:
    - SDK 1.x (>=1.50.0): Uses response.output_parsed
    - SDK 2.x (>=2.0.0): Extracts from response.output[*].content[*].json

    âœ… SALVAGE MODE: Prefers output_json but will salvage valid JSON from output_text.
    SDK 2.x sometimes wraps valid JSON as output_text - we validate and extract it.
    Validates all required keys and types before accepting salvaged JSON.
    """
    # Required keys and valid types for diagram schema
    REQUIRED_KEYS = {"type", "content", "title", "explanation", "width", "height"}
    VALID_TYPES = {"matplotlib", "svg", "latex", "graphviz"}

    def validate_diagram_json(obj):
        """Validate diagram JSON has all required keys with correct types."""
        if not isinstance(obj, dict):
            return False

        # Check all required keys present
        if not REQUIRED_KEYS.issubset(obj.keys()):
            missing = REQUIRED_KEYS - obj.keys()
            logger.debug(f"âš ï¸ Missing required keys: {missing}")
            return False

        # Validate types
        if obj["type"] not in VALID_TYPES:
            logger.debug(f"âš ï¸ Invalid type: {obj['type']} (must be one of {VALID_TYPES})")
            return False

        if not isinstance(obj["content"], str) or len(obj["content"]) == 0:
            logger.debug(f"âš ï¸ content must be non-empty string")
            return False

        if not isinstance(obj["width"], int) or not (200 <= obj["width"] <= 4096):
            logger.debug(f"âš ï¸ width must be int in range [200, 4096]")
            return False

        if not isinstance(obj["height"], int) or not (200 <= obj["height"] <= 4096):
            logger.debug(f"âš ï¸ height must be int in range [200, 4096]")
            return False

        return True

    # 1.x path: output_parsed is available
    if hasattr(response, "output_parsed") and response.output_parsed is not None:
        logger.debug("âœ… Using output_parsed (SDK 1.x >=1.50.0)")
        return response.output_parsed

    # 2.x path: walk output blocks and find json content
    if hasattr(response, "output") and response.output:
        logger.debug("âš ï¸ output_parsed not available, walking output blocks (SDK 2.x)")
        for item in response.output:
            # item.content is usually a list of content parts
            content = getattr(item, "content", None)
            if not content:
                continue
            for part in content:
                # In schema mode (SDK 2.x), this is usually "output_json" or "json"
                part_type = getattr(part, "type", None)

                # âœ… PRIORITY: Accept proper schema output (output_json or json)
                if part_type in ("output_json", "json"):
                    # SDK 2.x: access part.json directly (already parsed dict)
                    if hasattr(part, "json"):
                        result = part.json
                        logger.debug(f"âœ… Extracted from part.json (type={part_type})")
                        return result

                # âœ… SALVAGE: Try to parse JSON from output_text before rejecting
                # SDK 2.x sometimes wraps valid JSON as output_text instead of output_json
                if part_type in ("output_text", "text") and hasattr(part, "text"):
                    text = part.text.strip()

                    # Handle leading/trailing junk: find first { and last }
                    first_brace = text.find("{")
                    last_brace = text.rfind("}")

                    if first_brace != -1 and last_brace != -1 and first_brace < last_brace:
                        json_candidate = text[first_brace:last_brace+1]
                        try:
                            obj = _json.loads(json_candidate)

                            # Validate it has all required diagram schema keys with correct types
                            if validate_diagram_json(obj):
                                logger.debug(f"âœ… Salvaged valid JSON from {part_type} block (SDK 2.x behavior)")
                                if first_brace > 0 or last_brace < len(text) - 1:
                                    logger.debug(f"   (stripped {first_brace} leading + {len(text)-last_brace-1} trailing chars)")
                                return obj
                            else:
                                logger.debug(f"âŒ Salvaged JSON failed validation")
                        except _json.JSONDecodeError as e:
                            logger.debug(f"âš ï¸ Found braces but invalid JSON: {e}")
                            pass  # Not valid JSON, continue to error

                    # If we get here, it's truly non-JSON text (preamble/explanation)
                    logger.debug(f"âŒ Schema violation: Received {part_type} block with non-JSON content")
                    raise ValueError(f"Schema mode failed: received {part_type} block instead of output_json")

    # If we reach here, schema was not respected - raise error to trigger fallback
    raise ValueError("Schema output missing (no output_json block found) - SDK version may be incompatible or schema not enforced")


async def generate_diagram_unified(conversation_text: str, diagram_request: str,
                                   subject: str, language: str, regenerate: bool = False,
                                   ai_service=None) -> Dict:
    """
    Unified diagram generation: AI chooses tool AND generates code in one call.

    Two modes:
    - Initial generation (regenerate=False): gpt-4o-mini, one-step, fast (optimized for speed)
    - Regeneration (regenerate=True): o4-mini, two-step reasoning (optimized for quality)

    Returns structured output: {"type": "matplotlib|svg|graphviz|latex", "content": "...", "reasoning": "..."}
    """
    # Language-specific instructions for explanations (NOT for diagram code)
    explanation_language_map = {
        'en': 'English',
        'zh-Hans': 'ç®€ä½“ä¸­æ–‡ (Simplified Chinese)',
        'zh-Hant': 'ç¹é«”ä¸­æ–‡ (Traditional Chinese)'
    }

    explanation_lang = explanation_language_map.get(language, 'English')

    # âœ… FIX: Use SAME prompt structure for both modes (no reasoning requirement)
    # Only difference: regenerate=True uses o4-mini for better quality
    # Both use Responses API with strict schema (no reasoning field - avoids schema violations)

    prompt = f"""You are an expert educational diagram generator.

**REQUEST**: {diagram_request}
**CONTEXT**: {conversation_text}
**SUBJECT**: {subject}

---

**AVAILABLE TOOLS**:

1. **matplotlib** - Math functions, graphs, plots, data visualization
   Best for: y = x^2, sin(x), histograms, scatter plots

2. **svg** - Geometric shapes, concept diagrams, simple illustrations
   Best for: triangles, circles, concept diagrams

3. **latex** (TikZ) - Geometric proofs, formal constructions
   Best for: theorem proofs, precise geometric diagrams

4. **graphviz** - Trees, graphs, flowcharts, hierarchies
   Best for: binary trees, flowcharts, state diagrams

---

**âš ï¸ CRITICAL: ASCII-ONLY TEXT IN CODE**
Server has NO unicode fonts. Use English/ASCII labels ONLY in diagram code.
- âŒ WRONG: plt.xlabel('å‡½æ•°') or 'cafÃ©' or 'é–¢æ•°' â†’ FAILS
- âœ… CORRECT: plt.xlabel('Function') or 'cafe' â†’ WORKS
- Title/explanation fields CAN use {explanation_lang} (user-facing)
- Code text (labels, legends, nodes) MUST be English/ASCII (rendering)

**REQUIREMENTS**:
- Choose appropriate "type": matplotlib, svg, latex, or graphviz
- Generate COMPLETE, executable code (imports, setup, all details)
- NO placeholders, TODOs, markdown fences, or backslash line continuations
- Output must be valid json (lowercase required)

**OUTPUT FORMAT**:
Return JSON only - no preamble, no markdown, no extra text.

Required keys (all must be present): type, content, title, explanation, width, height

Note: If a specific diagram type is truly impossible (e.g., 3D animation), choose the closest alternative tool."""

    try:
        # âœ… FIX: Define strict JSON schema WITHOUT reasoning field
        # Same schema for both generation and regeneration (no reasoning = no schema violations)
        diagram_schema = {
            "type": "object",
            "properties": {
                "type": {
                    "type": "string",
                    "enum": ["matplotlib", "svg", "latex", "graphviz"],
                    "description": "Chosen visualization tool"
                },
                "content": {
                    "type": "string",
                    "minLength": 10,
                    "description": "Complete executable code (ONLY ENGLISH TEXT in diagram)"
                },
                "title": {
                    "type": "string",
                    "minLength": 1,
                    "description": "Brief title for the diagram"
                },
                "explanation": {
                    "type": "string",
                    "minLength": 1,
                    "description": "Brief explanation of the diagram"
                },
                "width": {
                    "type": "integer",
                    "minimum": 200,
                    "maximum": 4096,
                    "description": "Suggested width in pixels"
                },
                "height": {
                    "type": "integer",
                    "minimum": 200,
                    "maximum": 4096,
                    "description": "Suggested height in pixels"
                }
            },
            "required": ["type", "content", "title", "explanation", "width", "height"],
            "additionalProperties": False
        }

        # Choose model and parameters based on regeneration mode
        has_responses_api = hasattr(ai_service.client, 'responses')

        if regenerate:
            # âœ… O4-MINI REGENERATION PATH (quality-focused)
            model = "o4-mini"
            max_completion_tokens = 1500
            logger.debug(f"ğŸ¤– Using model: {model} (regenerate=True, quality-focused)")

            # Required keys for validation
            REQUIRED_KEYS = {"type", "content", "title", "explanation", "width", "height"}

            def is_valid_response(text: str) -> tuple[bool, str]:
                """
                Validate o4-mini response is usable.
                Returns: (is_valid, error_message)
                """
                # Check empty/whitespace
                if not text or text.strip() == "":
                    return False, "empty or whitespace-only"

                # Check null
                if text.strip().lower() == "null":
                    return False, "returned 'null'"

                # Try to parse JSON
                try:
                    obj = _json.loads(text)
                except _json.JSONDecodeError as e:
                    return False, f"JSON parse error: {e}"

                # Check if empty object
                if obj == {}:
                    return False, "empty object '{}'"

                # Check required keys
                if not isinstance(obj, dict):
                    return False, f"not a dict, got {type(obj).__name__}"

                missing_keys = REQUIRED_KEYS - obj.keys()
                if missing_keys:
                    return False, f"missing required keys: {missing_keys}"

                return True, ""

            # âœ… RETRY: o4-mini with comprehensive validation
            result_text = None
            for attempt in range(2):
                response = await ai_service.client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt + ("\n\nReturn JSON now." if attempt > 0 else "")}],
                    max_completion_tokens=max_completion_tokens,
                    response_format={"type": "json_object"}
                )
                candidate_text = response.choices[0].message.content.strip()

                # ğŸ” DEBUG: Log raw o4-mini output
                logger.debug(f"ğŸ” [DEBUG] o4-mini attempt {attempt + 1} raw response (first 500 chars):")
                logger.debug(f"ğŸ” {candidate_text[:500]}")
                logger.debug(f"ğŸ” [DEBUG] Response type: {type(candidate_text)}, Length: {len(candidate_text)} chars")

                # Validate response
                is_valid, error_reason = is_valid_response(candidate_text)

                if is_valid:
                    result_text = candidate_text
                    logger.debug(f"âœ… o4-mini attempt {attempt + 1} returned valid JSON")
                    break
                else:
                    logger.debug(f"âŒ o4-mini attempt {attempt + 1} failed: {error_reason}")
                    if attempt < 1:
                        logger.debug(f"ğŸ”„ Retrying with explicit reminder...")

            # Final check after retries
            if not result_text:
                logger.debug(f"âŒ o4-mini failed after 2 attempts - using emergency fallback")
                raise ValueError("o4-mini returned invalid response after retries")
        else:
            # âœ… GPT-4O-MINI INITIAL GENERATION PATH (speed-focused)
            model = "gpt-4o-mini"
            max_tokens = 1200
            temperature = 0.2
            logger.debug(f"ğŸ¤– Using model: {model} (regenerate=False, speed-focused)")

            if has_responses_api:
                # Responses API with strict JSON schema
                logger.debug(f"âœ… Using Responses API with strict JSON schema")
                try:
                    response = await ai_service.client.responses.create(
                        model=model,
                        input=prompt,
                        temperature=temperature,
                        max_output_tokens=max_tokens,
                        text={
                            "format": {
                                "type": "json_schema",
                                "name": "diagram_generation",
                                "strict": True,
                                "schema": diagram_schema
                            }
                        }
                    )

                    # âœ… Use cross-version helper to extract JSON
                    result_obj = extract_json_from_responses(response)
                    result_text = _json.dumps(result_obj)  # Convert to JSON string for downstream code

                    # ğŸ” DEBUG: Log raw Responses API output
                    logger.debug(f"ğŸ” [DEBUG] gpt-4o-mini Responses API result (first 500 chars):")
                    logger.debug(f"ğŸ” {result_text[:500]}")
                    logger.debug(f"ğŸ” [DEBUG] Parsed type: {result_obj.get('type', 'unknown')}, Content length: {len(result_obj.get('content', ''))} chars")

                    logger.debug(f"âœ… Got result: {result_obj.get('type', 'unknown')} diagram")
                    logger.debug(f"âœ… Content length: {len(result_obj.get('content', ''))} chars")

                except Exception as e:
                    logger.debug(f"âŒ {model} Responses API failed: {type(e).__name__}: {e}")
                    logger.debug(f"âš ï¸ Falling back to chat.completions")
                    # Fallback to chat.completions
                    response = await ai_service.client.chat.completions.create(
                        model=model,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=temperature,
                        max_tokens=max_tokens,
                        response_format={"type": "json_object"}
                    )
                    result_text = response.choices[0].message.content.strip()

                    # ğŸ” DEBUG: Log fallback output
                    logger.debug(f"ğŸ” [DEBUG] gpt-4o-mini chat.completions fallback (first 500 chars):")
                    logger.debug(f"ğŸ” {result_text[:500]}")
                    logger.debug(f"ğŸ” [DEBUG] Response type: {type(result_text)}, Length: {len(result_text)} chars")
            else:
                # Fallback to chat.completions for old SDK
                logger.debug(f"âš ï¸ Responses API not available, using chat.completions (upgrade openai SDK to >=1.50.0)")
                response = await ai_service.client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=max_tokens,
                    response_format={"type": "json_object"}
                )
                result_text = response.choices[0].message.content.strip()

                # ğŸ” DEBUG: Log old SDK output
                logger.debug(f"ğŸ” [DEBUG] gpt-4o-mini old SDK chat.completions (first 500 chars):")
                logger.debug(f"ğŸ” {result_text[:500]}")
                logger.debug(f"ğŸ” [DEBUG] Response type: {type(result_text)}, Length: {len(result_text)} chars")

        # Parse JSON response
        # ğŸ” DEBUG: Final consolidated log before parsing
        logger.debug(f"ğŸ” [DEBUG] === FINAL JSON TO PARSE (first 800 chars) ===")
        logger.debug(f"ğŸ” {result_text[:800]}")
        logger.debug(f"ğŸ” [DEBUG] === END RAW OUTPUT ===")

        result = _json.loads(result_text)

        # Validate tool choice
        valid_tools = ['matplotlib', 'svg', 'latex', 'graphviz']
        chosen_tool = result.get('type', 'svg').lower()

        if chosen_tool not in valid_tools:
            logger.debug(f"âš ï¸ Invalid tool '{chosen_tool}', defaulting to SVG")
            chosen_tool = 'svg'

        logger.debug(f"âœ… AI chose: {chosen_tool}")
        logger.debug(f"   Title: {result.get('title', 'Untitled')}")

        # ğŸ” DEBUG: Log the actual generated code
        generated_code = result.get('content', '')
        logger.debug(f"ğŸ” [DEBUG] === GENERATED {chosen_tool.upper()} CODE (first 800 chars) ===")
        logger.debug(f"ğŸ” {generated_code[:800]}")
        logger.debug(f"ğŸ” [DEBUG] === END GENERATED CODE ===")
        logger.debug(f"ğŸ” [DEBUG] Full code length: {len(generated_code)} chars")

        # âœ… FIX: Safe token accounting across SDK versions
        tokens = getattr(getattr(response, "usage", None), "total_tokens", None)
        result['tokens_used'] = tokens if tokens is not None else 0

        return result

    except Exception as e:
        logger.debug(f"âŒ Unified generation failed: {e}")
        # Fallback to SVG
        return {
            'type': 'svg',
            'content': '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 400 300"><text x="200" y="150" text-anchor="middle">Diagram generation failed</text></svg>',
            'title': 'Generation Failed',
            'explanation': f'Failed to generate diagram: {str(e)}',
            'width': 400,
            'height': 300,
            'tokens_used': 0
        }


def analyze_content_for_diagram_type(conversation_text: str, subject: str) -> Dict[str, str]:
    """
    Smart routing: Choose the RIGHT tool for each diagram type.

    PHILOSOPHY: Match tool to task for 90%+ success rate
    - Geometric shapes â†’ SVG (vector graphics, perfect for shapes)
    - Math functions â†’ Matplotlib (data plotting, perfect for graphs)
    - Geometric proofs â†’ LaTeX (rare, precise constructions)
    """
    content_lower = conversation_text.lower()

    # ğŸ¯ PRIORITY 1: Geometric SHAPES â†’ SVG (best tool for vector shapes)
    geometric_shapes = ['triangle', 'ä¸‰è§’å½¢', 'circle', 'åœ†', 'rectangle', 'çŸ©å½¢', 'square', 'æ­£æ–¹å½¢',
                       'pentagon', 'äº”è¾¹å½¢', 'hexagon', 'å…­è¾¹å½¢', 'polygon', 'å¤šè¾¹å½¢', 'ellipse', 'æ¤­åœ†',
                       'diamond', 'è±å½¢', 'trapezoid', 'æ¢¯å½¢', 'parallelogram', 'å¹³è¡Œå››è¾¹å½¢']

    shape_verbs = ['draw', 'sketch', 'show', 'illustrate', 'ç”»', 'ç»˜åˆ¶', 'æ˜¾ç¤º']

    # Check if this is a request to draw a geometric shape
    has_shape_request = any(shape in content_lower for shape in geometric_shapes)
    has_draw_verb = any(verb in content_lower for verb in shape_verbs)

    # Check if it's a math function (should use matplotlib instead)
    has_math_function = any(indicator in content_lower for indicator in
                           ['y =', 'f(x) =', 'f(x)=', 'y=', 'plot', 'graph the', 'ç»˜åˆ¶å‡½æ•°', 'å‡½æ•°å›¾åƒ'])

    # If drawing geometric shapes (not math functions) â†’ SVG
    if has_shape_request and not has_math_function:
        logger.debug(f"ğŸ“Š [Routing] Geometric shape detected â†’ SVG")
        return {'diagram_type': 'svg', 'complexity': 'medium'}

    # ğŸ“ˆ PRIORITY 2: Mathematical FUNCTIONS â†’ Matplotlib (best for data plots)
    math_function_indicators = [
        'y =', 'f(x) =', 'f(x)=', 'y=', 'g(x) =',  # Function notation
        'plot', 'graph', 'curve', 'å‡½æ•°', 'å›¾åƒ', 'æ›²çº¿',  # Plotting keywords
        'parabola', 'quadratic', 'linear', 'exponential', 'logarithmic',  # Function types
        'sin(', 'cos(', 'tan(', 'e^', 'ln(', 'log(',  # Math functions
        'derivative', 'å¯¼æ•°', 'integral', 'ç§¯åˆ†'  # Calculus
    ]

    if any(indicator in content_lower for indicator in math_function_indicators):
        logger.debug(f"ğŸ“Š [Routing] Mathematical function detected â†’ Matplotlib")
        return {'diagram_type': 'matplotlib', 'complexity': 'high'}

    # ğŸ“ PRIORITY 3: Geometric PROOFS â†’ LaTeX (rare, precise constructions)
    latex_indicators = ['proof', 'è¯æ˜', 'theorem', 'å®šç†', 'perpendicular', 'å‚ç›´',
                       'parallel', 'å¹³è¡Œ', 'congruent', 'å…¨ç­‰', 'similar', 'ç›¸ä¼¼']

    if any(indicator in content_lower for indicator in latex_indicators):
        logger.debug(f"ğŸ“Š [Routing] Geometric proof detected â†’ LaTeX")
        return {'diagram_type': 'latex', 'complexity': 'high'}

    # ğŸ“Š PRIORITY 4: Subject-based defaults
    if subject in ['mathematics', 'math', 'æ•°å­¦']:
        # Math subject: Try matplotlib first (good for most math content)
        logger.debug(f"ğŸ“Š [Routing] Math subject â†’ Matplotlib")
        return {'diagram_type': 'matplotlib', 'complexity': 'medium'}

    if subject in ['physics', 'ç‰©ç†', 'chemistry', 'åŒ–å­¦']:
        # Science subjects: SVG is flexible for diagrams
        logger.debug(f"ğŸ“Š [Routing] Science subject â†’ SVG")
        return {'diagram_type': 'svg', 'complexity': 'medium'}

    # ğŸ¨ DEFAULT: SVG (most flexible for general diagrams)
    # SVG handles: shapes, concepts, flowcharts, diagrams, illustrations
    logger.debug(f"ğŸ“Š [Routing] General request â†’ SVG (default)")
    return {'diagram_type': 'svg', 'complexity': 'medium'}


async def generate_latex_diagram(conversation_text: str, diagram_request: str,
                                subject: str, language: str, complexity: str,
                                ai_service=None, latex_converter=None) -> Dict:
    """
    Generate LaTeX/TikZ diagram for complex mathematical content.
    """
    language_instructions = {
        'en': 'Generate comments and labels in English.',
        'zh-Hans': 'ä½¿ç”¨ç®€ä½“ä¸­æ–‡ç”Ÿæˆæ³¨é‡Šå’Œæ ‡ç­¾ã€‚',
        'zh-Hant': 'ä½¿ç”¨ç¹é«”ä¸­æ–‡ç”Ÿæˆè¨»é‡‹å’Œæ¨™ç±¤ã€‚'
    }

    language_instruction = language_instructions.get(language, language_instructions['en'])

    prompt = f"""Based on this educational conversation, generate LaTeX/TikZ code for rendering.

CONVERSATION CONTEXT:
{conversation_text}

DIAGRAM REQUEST: {diagram_request}
SUBJECT: {subject}
COMPLEXITY: {complexity}

{language_instruction}

âš ï¸ CRITICAL - TIKZ REQUIREMENTS:
You MUST generate ONLY the TikZ picture code, NOT a full LaTeX document.

âŒ DO NOT USE:
- \\documentclass{{...}}
- \\begin{{document}} ... \\end{{document}}
- \\usepackage{{...}}

âœ… DO USE:
- Pure TikZ code: \\begin{{tikzpicture}} ... \\end{{tikzpicture}}
- Math mode delimiters: \\[ ... \\] or $ ... $
- TikZ libraries (axis, arrows, decorations)
- Coordinate systems and plotting

REQUIREMENTS:
1. Start directly with \\begin{{tikzpicture}}
2. Calculate and center on critical features
3. Include axis labels and critical point markers
4. Use appropriate scale for mobile viewing
5. Add annotations for important features
6. Use proper mathematical notation

Format your response as a JSON object with the structure shown above.

IMPORTANT: Return ONLY the JSON object, no other text."""

    # âœ… STABILITY IMPROVEMENT: Add retry logic for better reliability
    max_retries = 2
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.debug(f"ğŸ¨ [LaTeXDiagram] Attempt {attempt + 1}/{max_retries}")

            response = await ai_service.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=2000,
                response_format={"type": "json_object"}
            )

            result_text = response.choices[0].message.content.strip()
            logger.debug(f"ğŸ¨ [LaTeXDiagram] Response length: {len(result_text)} chars")

            # Parse JSON response
            result = _json.loads(result_text)

            # âœ… VALIDATION: Check for required fields
            if not result.get('diagram_code'):
                raise ValueError("Missing diagram_code in response")

            # âœ… VALIDATION: Check if LaTeX code is valid
            latex_code = result['diagram_code']
            required_patterns = ['\\begin{', '\\end{']
            if not any(pattern in latex_code for pattern in required_patterns):
                raise ValueError(f"Invalid LaTeX format - missing \\begin or \\end tags")

            result['tokens_used'] = response.usage.total_tokens
            logger.debug(f"âœ… [LaTeXDiagram] Valid LaTeX generated on attempt {attempt + 1}")

            # ğŸš€ Convert LaTeX to SVG for client-side rendering
            logger.debug(f"ğŸ”„ [LaTeXDiagram] Converting LaTeX to SVG...")

            conversion_result = await latex_converter.convert_tikz_to_svg(
                tikz_code=latex_code,
                title=result.get('diagram_title', 'Diagram'),
                width=result.get('width', 400),
                height=result.get('height', 300)
            )

            if conversion_result['success']:
                # Return as SVG so iOS can render it easily
                logger.debug(f"âœ… [LaTeXDiagram] Converted to SVG successfully")
                result['diagram_type'] = 'svg'  # Change type to SVG
                result['diagram_code'] = conversion_result['svg_code']
                result['latex_source'] = latex_code  # Keep original LaTeX for reference
                return result
            else:
                # Conversion failed, return original LaTeX (iOS will try to render)
                logger.debug(f"âš ï¸ [LaTeXDiagram] SVG conversion failed: {conversion_result['error']}")
                logger.debug(f"   Returning original LaTeX code for client-side rendering")
                return result

        except Exception as e:
            last_error = e
            logger.debug(f"âš ï¸ [LaTeXDiagram] Attempt {attempt + 1} failed: {str(e)}")
            if attempt < max_retries - 1:
                logger.debug(f"ğŸ”„ [LaTeXDiagram] Retrying...")
                continue

    # All retries failed - return error fallback
    logger.debug(f"âŒ [LaTeXDiagram] All {max_retries} attempts failed: {last_error}")
    return {
        'diagram_type': 'latex',
        'diagram_code': '\\text{Diagram generation failed. Please try again.}',
        'diagram_title': 'Generation Failed',
        'explanation': f'Failed to generate LaTeX diagram after {max_retries} attempts: {str(last_error)}',
        'width': 400,
        'height': 300,
        'tokens_used': 0
    }


async def generate_svg_diagram(conversation_text: str, diagram_request: str,
                              subject: str, language: str, complexity: str,
                              ai_service=None) -> Dict:
    """
    Generate SVG diagram for geometric shapes and simple visualizations.
    """
    language_instructions = {
        'en': 'Use English for all text labels and annotations.',
        'zh-Hans': 'ä½¿ç”¨ç®€ä½“ä¸­æ–‡ä½œä¸ºæ‰€æœ‰æ–‡å­—æ ‡ç­¾å’Œæ³¨é‡Šã€‚',
        'zh-Hant': 'ä½¿ç”¨ç¹é«”ä¸­æ–‡ä½œç‚ºæ‰€æœ‰æ–‡å­—æ¨™ç±¤å’Œè¨»é‡‹ã€‚'
    }

    language_instruction = language_instructions.get(language, language_instructions['en'])

    # âœ… VALIDATION: Check if this should actually be LaTeX
    if any(kw in conversation_text.lower() for kw in ['y =', 'f(x) =', 'parabola', 'quadratic function']):
        logger.debug(f"âš ï¸ [SVGDiagram] Warning: Mathematical function detected, LaTeX might be better")
        logger.debug(f"   Conversation contains function notation - consider using LaTeX instead")

    prompt = f"""Based on this educational conversation, generate an SVG diagram to help visualize the concept.

CONVERSATION CONTEXT:
{conversation_text}

DIAGRAM REQUEST: {diagram_request}
SUBJECT: {subject}
COMPLEXITY: {complexity}

{language_instruction}

**TRY YOUR BEST** - SVG is flexible! Make reasonable assumptions if some details are missing.
You can draw: geometric shapes, concept diagrams, flowcharts, simple illustrations, graphs, etc.

Generate a complete, valid SVG diagram that:
1. Clearly illustrates the main concept from the conversation
2. Uses appropriate geometric shapes and lines
3. Includes clear labels and annotations
4. Is educational and visually appealing
5. Works on mobile devices (responsive)
6. **Makes reasonable assumptions** if exact dimensions or details aren't specified

Format your response as a JSON object:
{{
    "diagram_type": "svg",
    "diagram_code": "<svg xmlns=\\"http://www.w3.org/2000/svg\\" viewBox=\\"-4 -1 4 8\\">...</svg>",
    "diagram_title": "Clear title for the diagram",
    "explanation": "Brief explanation of what the diagram shows",
    "width": 400,
    "height": 300,
    "background": "white"
}}

IMPORTANT: Return ONLY the JSON object, no other text."""

    # âœ… STABILITY IMPROVEMENT: Add retry logic for better reliability
    max_retries = 2
    last_error = None

    for attempt in range(max_retries):
        try:
            logger.debug(f"ğŸ¨ [SVGDiagram] Attempt {attempt + 1}/{max_retries}")

            response = await ai_service.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=1800,
                response_format={"type": "json_object"}
            )

            result_text = response.choices[0].message.content.strip()
            logger.debug(f"ğŸ¨ [SVGDiagram] Response length: {len(result_text)} chars")

            # Parse JSON response
            result = _json.loads(result_text)

            # âœ… VALIDATION: Check for required fields
            if not result.get('diagram_code'):
                raise ValueError("Missing diagram_code in response")

            # âœ… VALIDATION: Check if SVG code is valid
            svg_code = result['diagram_code']
            if not svg_code.strip().lower().startswith('<svg'):
                raise ValueError(f"Invalid SVG format - missing <svg> tag")

            # âœ… VALIDATION: Check for closing tag
            if '</svg>' not in svg_code.lower():
                raise ValueError(f"Invalid SVG format - missing </svg> tag")

            result['tokens_used'] = response.usage.total_tokens
            logger.debug(f"âœ… [SVGDiagram] Valid SVG generated on attempt {attempt + 1}")
            return result

        except Exception as e:
            last_error = e
            logger.debug(f"âš ï¸ [SVGDiagram] Attempt {attempt + 1} failed: {str(e)}")
            if attempt < max_retries - 1:
                logger.debug(f"ğŸ”„ [SVGDiagram] Retrying...")
                continue

    # All retries failed - return error fallback
    logger.debug(f"âŒ [SVGDiagram] All {max_retries} attempts failed: {last_error}")
    return {
        'diagram_type': 'svg',
        'diagram_code': '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 400 300"><rect width="400" height="300" fill="white"/><text x="200" y="150" text-anchor="middle" font-size="14" fill="gray">Diagram generation failed. Please try again.</text></svg>',
        'diagram_title': 'Generation Failed',
        'explanation': f'Failed to generate diagram after {max_retries} attempts: {str(last_error)}',
        'width': 400,
        'height': 300,
        'tokens_used': 0
    }
